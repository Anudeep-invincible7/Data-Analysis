{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I144d0BB6h35"
   },
   "source": [
    "## 1. Formation of questions based on Nouns and Verbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Vwk_xR3l6gdf"
   },
   "outputs": [],
   "source": [
    "##### Sample input text is given here. Please change the text input as per your requirement accordingly to generate questions.\n",
    "text = \"\"\"Socrates was born in 470 or 469 BC to Sophroniscus and Phaenarete, a stoneworker and a midwife, respectively, in the Athenian deme of Alopece; therefore, he was an Athenian citizen, having been born to relatively affluent Athenians. He lived close to his father's relatives and inherited, as was customary, part of his father's estate, securing a life reasonably free of financial concerns. His education followed the laws and customs of Athens. He learned the basic skills of reading and writing and, like most wealthy Athenians, received extra lessons in various other fields such as gymnastics, poetry and music. He was married twice (which came first is not clear): his marriage to Xanthippe took place when Socrates was in his fifties, and another marriage was with a daughter of Aristides, an Athenian statesman.”\"\"\"\n",
    "#text=\"\"\"There is a lot of volcanic activity at divergent plate boundaries in the oceans. For example, many undersea volcanoes are found along the Mid-Atlantic Ridge. This is a divergent plate boundary that runs north-south through the middle of the Atlantic Ocean. As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the crust. Molten rock, called magma, erupts through these cracks onto Earth’s surface. At the surface, the molten rock is called lava. It cools and hardens, forming rock. Divergent plate boundaries also occur in the continental crust. Volcanoes form at these boundaries, but less often than in ocean crust. That’s because continental crust is thicker than oceanic crust. This makes it more difficult for molten rock to push up through the crust. Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a subduction zone. The leading edge of the plate melts as it is pulled into the mantle, forming magma that erupts as volcanoes. When a line of volcanoes forms along a subduction zone, they make up a volcanic arc. The edges of the Pacific plate are long subduction zones lined with volcanoes. This is why the Pacific rim is called the “Pacific Ring of Fire.”\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "FtP8QFUkPzAk"
   },
   "outputs": [],
   "source": [
    "#nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0GpMMllApOt"
   },
   "source": [
    "## Installation of all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYS-YoSPcj3s",
    "outputId": "083b3655-ab4f-454f-adac-d0c26f43e47c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: spacy==2.2.4 in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (7.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (3.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.7)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (2.23.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.21.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (2.0.6)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (0.9.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (57.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (4.64.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (3.0.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting en_core_web_sm==2.2.5\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.0 MB 781 kB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.1.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# This cell is highlighting the commas,periods and other puntuations presented in the sentences\n",
    "#loaded english webtext pipeling to process the text\n",
    "!pip install spacy==2.2.4\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "text_spacy = text\n",
    "doc = nlp(text_spacy)\n",
    "a=list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZyARWvqdIo2",
    "outputId": "28695f54-0e53-4296-dc3d-d866c2028752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Socrates was born in 470 or 469 BC to Sophroniscus and Phaenarete, a stoneworker and a midwife, respectively, in the Athenian deme of Alopece; therefore, he was an Athenian\n",
      "citizen, having been born to relatively affluent Athenians. He lived close to his father's relatives and inherited, as was customary, part of his father's estate, securing a\n",
      "life reasonably free of financial concerns. His education followed the laws and customs of Athens. He learned the basic skills of reading and writing and, like most wealthy\n",
      "Athenians, received extra lessons in various other fields such as gymnastics, poetry and music. He was married twice (which came first is not clear): his marriage to Xanthippe\n",
      "took place when Socrates was in his fifties, and another marriage was with a daughter of Aristides, an Athenian statesman.”\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "text_wrap = textwrap.TextWrapper(width=175)\n",
    "sent_list = text_wrap.wrap(text=text)\n",
    "wrapped=[print(sentences) for sentences in sent_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "a3IszhHJSiEB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tx1eN_2S7aep",
    "outputId": "b65dab56-c0ed-495b-f884-aa6514ba06cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================== Info about spaCy ==============================\u001b[0m\n",
      "\n",
      "spaCy version    2.2.4                         \n",
      "Location         /usr/local/lib/python3.7/dist-packages/spacy\n",
      "Platform         Linux-5.4.188+-x86_64-with-Ubuntu-18.04-bionic\n",
      "Python version   3.7.13                        \n",
      "Models                                         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qMqzqZ6fKhN",
    "outputId": "802be68f-421e-4128-8ae6-9ef977e8f7d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Installing pke library for the python keyword extraction from external source github https://github.com/boudinfl/pke\n",
    "\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from flashtext import KeywordProcessor\n",
    "import string\n",
    "import itertools\n",
    "!pip install --quiet git+https://github.com/boudinfl/pke.git@dc4d5f21e0ffe64c4df93c46146d29d1c522476b\n",
    "!pip install --quiet flashtext==2.7\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "import pke\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZIdwVViamBHC",
    "outputId": "dca43054-7668-4883-817a-729a8ab155fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n",
      "157\n",
      "54\n",
      "169\n",
      "203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Socrates was born in 470 or 469 BC to Sophroniscus and Phaenarete, a stoneworker and a midwife, respectively, in the Athenian deme of Alopece; therefore, he was an Athenian citizen, having been born to relatively affluent Athenians.',\n",
       " \"He lived close to his father's relatives and inherited, as was customary, part of his father's estate, securing a life reasonably free of financial concerns.\",\n",
       " 'His education followed the laws and customs of Athens.',\n",
       " 'He learned the basic skills of reading and writing and, like most wealthy Athenians, received extra lessons in various other fields such as gymnastics, poetry and music.',\n",
       " 'He was married twice (which came first is not clear): his marriage to Xanthippe took place when Socrates was in his fifties, and another marriage was with a daughter of Aristides, an Athenian statesman.”']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Excluding the sentences which are having length less than 30\n",
    "## So that our creation of question wont confuse the readers if they are big and understandable meaningful sentences\n",
    "sent_list = text_wrap.wrap(text=text)\n",
    "sent_list=sent_tokenize(text)\n",
    "main_sent=[]\n",
    "for sentences in sent_list:\n",
    "    print(len(sentences))\n",
    "    if len(sentences) > 30:\n",
    "        main_sent.append(sentences.strip())\n",
    "main_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GG0CsDLcFvMR",
    "outputId": "8e8d03b8-89d7-4928-88e6-764f3a221b4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNlUIX1qDNPn",
    "outputId": "a037cac6-9c15-41a3-dbba-195c336ad92e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['socrates', 'bc', 'sophroniscus', 'phaenarete', 'athenian', 'alopece', 'athenian', 'athenians', \"father 's relatives\", \"father 's estate\", 'athens', 'basic skills', 'athenians', 'extra lessons', 'xanthippe', 'socrates', 'aristides', 'athenian'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Extracting all the noun phrases present in the text by using text blob library.\n",
    "from textblob import TextBlob\n",
    "blob = TextBlob(text)\n",
    "noun_phrases=blob.noun_phrases\n",
    "noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChAZN_fzBCti"
   },
   "source": [
    "## Extraction of Keywords using position tag of NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zLax3AsIGdtX",
    "outputId": "be808302-5b85-4abe-bc23-57cfdccd232c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words which are verbs present in the text (with duplicate elements):  ['having', 'securing', 'followed', 'learned', 'received', 'married', 'Xanthippe']\n",
      "Words which are Nouns present in the text (with duplicate elements):  ['Socrates', 'Sophroniscus', 'Phaenarete', 'stoneworker', 'midwife', 'Alopece', 'citizen', 'Athenians', 'father', 'relatives', 'father', 'estate', 'concerns', 'education', 'customs', 'Athens', 'skills', 'reading', 'writing', 'Athenians', 'lessons', 'fields', 'gymnastics', 'poetry', 'marriage', 'Socrates', 'fifties', 'marriage', 'daughter', 'Aristides', 'statesman']\n",
      "Words which are verbs present in the text:  ['having', 'securing', 'followed', 'learned', 'received', 'married', 'Xanthippe']\n",
      "Words which are Nouns present in the text:  ['Socrates', 'Sophroniscus', 'Phaenarete', 'stoneworker', 'midwife', 'Alopece', 'citizen', 'Athenians', 'father', 'relatives', 'estate', 'concerns', 'education', 'customs', 'Athens', 'skills', 'reading', 'writing', 'lessons', 'fields', 'gymnastics', 'poetry', 'marriage', 'fifties', 'daughter', 'Aristides', 'statesman']\n"
     ]
    }
   ],
   "source": [
    "#Extracting all the nouns and verbs present in the text using nltk,pos_tag \n",
    "wrd_tokenize=nltk.word_tokenize(text)\n",
    "position_parts_of_speech=nltk.pos_tag(wrd_tokenize)\n",
    "verb_words_with_duplicates=[]\n",
    "noun_words_with_duplicates=[]\n",
    "for (word,pos) in position_parts_of_speech:\n",
    "  if pos[0]== 'V': ##Extracting key words of verbs\n",
    "    if(len(word)>5):\n",
    "        verb_words_with_duplicates.append(word)\n",
    "  if pos[0]=='N':  ##Extracting key words of Nouns\n",
    "    if(len(word)>5):\n",
    "        noun_words_with_duplicates.append(word)\n",
    "verb_words=[]\n",
    "noun_words=[]\n",
    "for words in verb_words_with_duplicates:\n",
    "  if words not in verb_words:\n",
    "    verb_words.append(words)\n",
    "for words in noun_words_with_duplicates:\n",
    "  if words not in noun_words:\n",
    "    noun_words.append(words)\n",
    "print('Words which are verbs present in the text (with duplicate elements): ',verb_words_with_duplicates)\n",
    "print('Words which are Nouns present in the text (with duplicate elements): ',noun_words_with_duplicates)\n",
    "print('Words which are verbs present in the text: ',verb_words)\n",
    "print('Words which are Nouns present in the text: ',noun_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxQE7pPPBRNq"
   },
   "source": [
    "## Extraction of Keywords using Python keyword extractor (PKE) Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPlXWNaTNtTk",
    "outputId": "0124d18e-f471-4818-d352-e79c6ca6dba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyphrases in the text:  ['father', 'athenian deme', 'marriage', 'securing', 'life', 'estate', 'free', 'born', 'financial concerns', 'education followed', 'laws', 'part', 'relatives', 'basic skills', 'customary', 'inherited', 'reading', 'customs', 'poetry', 'learned', 'music', 'writing', 'lived', 'gymnastics', 'affluent', 'married', 'midwife', 'came', 'clear', 'aristides']\n"
     ]
    }
   ],
   "source": [
    "# ### using istalled pke library from the git\n",
    "# ### I am extracting only the words of part speech belongs to Verb, Adjective and Noun\n",
    "# ### Creating stop words as they dont add much weightage\n",
    "\n",
    "def pos_words_generation(text):\n",
    "    out=[]    \n",
    "    stop_list_punct_duplicates = []\n",
    "    stop_list_punct= []\n",
    "    for words in nltk.word_tokenize(text):\n",
    "      if words in list(string.punctuation):\n",
    "         stop_list_punct_duplicates.append(words)\n",
    "    for w in stop_list_punct_duplicates:\n",
    "      if w not in stop_list_punct:\n",
    "         stop_list_punct.append(w)\n",
    "    pos_word_getter = pke.unsupervised.MultipartiteRank()\n",
    "    pos_word_getter.load_document(input=text)\n",
    "    brackets=['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
    "    stop_list1=brackets\n",
    "    stop_list2=stopwords.words('english')\n",
    "    stop_list=stop_list_punct + stop_list1 + stop_list2\n",
    "    position_vector = {'VERB','ADJ','NOUN'}\n",
    "    pos_word_getter.candidate_selection(pos=position_vector, stoplist=stop_list)\n",
    "    pos_word_getter.candidate_weighting(alpha=1.1,threshold=0.75,method='average')\n",
    "    keyphrases = pos_word_getter.get_n_best(n=30)\n",
    "    for val in keyphrases:\n",
    "        out.append(val[0])\n",
    "\n",
    "    if len(out)==0:\n",
    "      print('No words for given Parts of speech present in the text!')\n",
    "\n",
    "    return out\n",
    "\n",
    "sent_V_A_N = pos_words_generation(text)\n",
    "print('keyphrases in the text: ',sent_V_A_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fxP0g9O_Odv"
   },
   "source": [
    "#### We are comparing both the words generated by PKE library and pos_tag of NLTK. Either it is Verb (V) or Noun (N) as we give below, Our code generates the set of keywords only if they are present in the both the result sets to gain more accuracy.\n",
    "\n",
    "\n",
    "\n",
    "**Please provide the option of whether the generation of keywords based on Nouns or Verbs,present in the each sentence of the paragraph, where the comment is provided.Give input as 'N' for Noun or 'V' for verb...** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rj7UFzzN-Wb",
    "outputId": "fa69800e-c7da-4f33-eb94-941933d696e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['midwife', 'father', 'relatives', 'estate', 'customs', 'reading', 'writing', 'gymnastics', 'poetry', 'marriage']\n",
      "{'customs': ['His education followed the laws and customs of Athens.'],\n",
      " 'estate': [\"He lived close to his father's relatives and inherited, as was \"\n",
      "            \"customary, part of his father's estate, securing a life \"\n",
      "            'reasonably free of financial concerns.'],\n",
      " 'father': [\"He lived close to his father's relatives and inherited, as was \"\n",
      "            \"customary, part of his father's estate, securing a life \"\n",
      "            'reasonably free of financial concerns.',\n",
      "            \"He lived close to his father's relatives and inherited, as was \"\n",
      "            \"customary, part of his father's estate, securing a life \"\n",
      "            'reasonably free of financial concerns.'],\n",
      " 'gymnastics': ['He learned the basic skills of reading and writing and, like '\n",
      "                'most wealthy Athenians, received extra lessons in various '\n",
      "                'other fields such as gymnastics, poetry and music.'],\n",
      " 'marriage': ['He was married twice (which came first is not clear): his '\n",
      "              'marriage to Xanthippe took place when Socrates was in his '\n",
      "              'fifties, and another marriage was with a daughter of Aristides, '\n",
      "              'an Athenian statesman.”',\n",
      "              'He was married twice (which came first is not clear): his '\n",
      "              'marriage to Xanthippe took place when Socrates was in his '\n",
      "              'fifties, and another marriage was with a daughter of Aristides, '\n",
      "              'an Athenian statesman.”'],\n",
      " 'midwife': ['Socrates was born in 470 or 469 BC to Sophroniscus and '\n",
      "             'Phaenarete, a stoneworker and a midwife, respectively, in the '\n",
      "             'Athenian deme of Alopece; therefore, he was an Athenian citizen, '\n",
      "             'having been born to relatively affluent Athenians.'],\n",
      " 'poetry': ['He learned the basic skills of reading and writing and, like most '\n",
      "            'wealthy Athenians, received extra lessons in various other fields '\n",
      "            'such as gymnastics, poetry and music.'],\n",
      " 'reading': ['He learned the basic skills of reading and writing and, like '\n",
      "             'most wealthy Athenians, received extra lessons in various other '\n",
      "             'fields such as gymnastics, poetry and music.'],\n",
      " 'relatives': [\"He lived close to his father's relatives and inherited, as was \"\n",
      "               \"customary, part of his father's estate, securing a life \"\n",
      "               'reasonably free of financial concerns.'],\n",
      " 'writing': ['He learned the basic skills of reading and writing and, like '\n",
      "             'most wealthy Athenians, received extra lessons in various other '\n",
      "             'fields such as gymnastics, poetry and music.']}\n"
     ]
    }
   ],
   "source": [
    "#importing pprint for the sentences to be arranged in easily readable way.\n",
    "#This cell will extract all the sentences which are containing the keyphrases we generated in the above cell.\n",
    "#Sorting the sentences in a way that longer length first then shorter length next so that they can be easily readable.\n",
    "\n",
    "keyword_process = KeywordProcessor()\n",
    "sentences_with_keyword = {}\n",
    "keyword_text=[]\n",
    "\n",
    "from pprint import pprint\n",
    "def Parts_of_speech_words(wordlist_nouns,wordlist_verbs,main,pos):\n",
    "  keyword_text_processed=[]\n",
    "\n",
    "  if pos=='N':\n",
    "     for words_n in wordlist_nouns:\n",
    "        for words in main:\n",
    "           if (words_n == words):\n",
    "             keyword_text_processed.append(words_n)\n",
    "\n",
    "  if pos=='V':\n",
    "     for words_v in wordlist_verbs:\n",
    "        for words in main:\n",
    "           if (words_v == words):\n",
    "            keyword_text_processed.append(words_v)\n",
    "  return keyword_text_processed\n",
    "\n",
    "keyword_text=Parts_of_speech_words(noun_words,verb_words,sent_V_A_N,'N') #<--------------------- Are we framing questions with Nouns or Verbs, if nouns give 'N' else 'V'\n",
    "\n",
    "print(keyword_text)\n",
    "\n",
    "for word in keyword_text:\n",
    "    if len(word)>4: #not passing small words, it would make testing system too predictable if it has small meaning\n",
    "       sentences_with_keyword[word]=[]\n",
    "       keyword_process.add_keyword(word)\n",
    "         \n",
    "for lines in main_sent:  \n",
    "    present_keywords=keyword_process.extract_keywords(lines)\n",
    "    \n",
    "    for key in present_keywords:\n",
    "        sentences_with_keyword[key].append(lines) \n",
    "pprint (sentences_with_keyword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsBj1LbctgQi",
    "outputId": "053c0552-aa01-444b-9581-9a081a965a1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midwife\n",
      "father\n",
      "relatives\n",
      "estate\n",
      "customs\n",
      "reading\n",
      "writing\n",
      "gymnastics\n",
      "poetry\n",
      "marriage\n",
      "{'keys': ['midwife', 'relatives', 'customs', 'reading'],\n",
      " 'sentences': ['Socrates was born in 470 or 469 BC to Sophroniscus and '\n",
      "               'Phaenarete, a stoneworker and a .................. , '\n",
      "               'respectively, in the Athenian deme of Alopece; therefore, he '\n",
      "               'was an Athenian citizen, having been born to relatively '\n",
      "               'affluent Athenians.',\n",
      "               \"He lived close to his father's ..................  and \"\n",
      "               \"inherited, as was customary, part of his father's estate, \"\n",
      "               'securing a life reasonably free of financial concerns.',\n",
      "               'His education followed the laws and ..................  of '\n",
      "               'Athens.',\n",
      "               'He learned the basic skills of ..................  and writing '\n",
      "               'and, like most wealthy Athenians, received extra lessons in '\n",
      "               'various other fields such as gymnastics, poetry and music.'],\n",
      " 'title': 'Choose a right word for the missing part of the sentences'}\n"
     ]
    }
   ],
   "source": [
    "def pick_right_word(MatchedSent):\n",
    "    ques_generation={\"title\":\"Choose a right word for the missing part of the sentences\"}\n",
    "    blank_sentences = []\n",
    "    formed_sentences = []\n",
    "    keys=[]\n",
    "    formed_sentences_with_answers=[]\n",
    "    for key in MatchedSent.keys():\n",
    "      print(key)\n",
    "      if len(MatchedSent[key])>0:\n",
    "         length=MatchedSent[key]\n",
    "         length=sorted(length,key=len,reverse=True)\n",
    "         MatchedSent[key]=length\n",
    "\n",
    " #### This code can replace even if 2 keywords present in the same sentence \n",
    " #### It will test the student better if 2 cloze questions present in the same sentence of the paragraph.       \n",
    "    for key in MatchedSent:\n",
    "            main_sentence = MatchedSent[key][0]\n",
    "            Top_sentence = main_sentence\n",
    "            blank_sent = re.compile(re.escape(key), re.IGNORECASE)\n",
    "            count_word_per_sentence =  len(re.findall(re.escape(key),Top_sentence,re.IGNORECASE))\n",
    "            line = blank_sent.sub('.................. ', Top_sentence)\n",
    "            if (MatchedSent[key][0] not in formed_sentences) and count_word_per_sentence<3:\n",
    "                formed_sentences_with_answers.append(MatchedSent[key][0]) ###appending all the  sentences which are generating questions in fill_in_the_blanks\n",
    "\n",
    "                if count_word_per_sentence==2:\n",
    "                  continue\n",
    "                blank_sentences.append(line)\n",
    "                formed_sentences.append(MatchedSent[key][0])\n",
    "                keys.append(key)\n",
    "                \n",
    "    ques_generation[\"sentences\"]=blank_sentences[:10]\n",
    "    ques_generation[\"keys\"]=keys[:10]\n",
    "    return ques_generation,formed_sentences_with_answers\n",
    "fill_in_the_blanks,formed_sentences_with_answers = pick_right_word(sentences_with_keyword)\n",
    "pprint(fill_in_the_blanks)\n",
    "final_sentences=[]\n",
    "for sent in formed_sentences_with_answers:\n",
    "  if sent not in final_sentences:\n",
    "    final_sentences.append(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMifkMb6CIPK"
   },
   "source": [
    "## Shuffling of the answers and presenting the question format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YcNPsZB_uTe3",
    "outputId": "f71b5700-1da3-4489-e078-e9257756e1ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mPick the right word for the below sentences where the space is provided (Note: All the below questions are extracted from same context): \u001b[0m \u001b[1m\u001b[34m['midwife', 'relatives', 'reading', 'customs']\u001b[0m\n",
      "\n",
      "1. Socrates was born in 470 or 469 BC to Sophroniscus and Phaenarete, a stoneworker and a .................. , respectively, in the Athenian deme of Alopece; therefore, he was an Athenian citizen, having been born to relatively affluent Athenians.\n",
      "\n",
      "2. He lived close to his father's ..................  and inherited, as was customary, part of his father's estate, securing a life reasonably free of financial concerns.\n",
      "\n",
      "3. His education followed the laws and ..................  of Athens.\n",
      "\n",
      "4. He learned the basic skills of ..................  and writing and, like most wealthy Athenians, received extra lessons in various other fields such as gymnastics, poetry and music.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from termcolor import colored\n",
    "shuffle_list=[]\n",
    "for words in fill_in_the_blanks['keys']: ###shuffling and reshuffling to avoid same sequence of answers appear as per the blanks provided\n",
    "  shuffle_list.append(words)\n",
    "if random.shuffle(shuffle_list)==shuffle_list:\n",
    "  random.shuffle(shuffle_list)\n",
    "heading=colored('Pick the right word for the below sentences where the space is provided (Note: All the below questions are extracted from same context): ','red',attrs=['bold'])\n",
    "shuffle_color = colored(shuffle_list,'blue',attrs=['bold'])\n",
    "print(heading,'{}\\n'.format(shuffle_color))\n",
    "for a, b in enumerate((s for s in fill_in_the_blanks['sentences']), 1):\n",
    "    print('{}. {}\\n'.format(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wl70m590ETgN"
   },
   "source": [
    "## Sample generation of questions from pre-trained model using the sentences generated from the above process.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTkyEuDc3YkX",
    "outputId": "870b1f7d-7bb6-4edc-aca5-f63062b57220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "## Please note that we are generating questions from a pre-trained model. Our model of generating using pipeline will be provided (Work in progress as of now)\n",
    "\n",
    "\n",
    "!pip install --quiet git+https://github.com/huggingface/transformers.git@5c00918681d6b4027701eb46cea8f795da0d4064\n",
    "!pip install --quiet sentencepiece==0.1.95\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "main_model='ramsrigouthamg/t5_squad_v1' #we are downloading this pre-trained model from hugging face\n",
    "question_gen = T5ForConditionalGeneration.from_pretrained(main_model)\n",
    "question_tokenizer = T5Tokenizer.from_pretrained(main_model)\n",
    "def get_question(sentence,answer,mdl,tknizer):\n",
    "  text = \"context: {} answer: {}\".format(sentence,answer)\n",
    "  print (text)\n",
    "  max_len = 300\n",
    "  encoding = tknizer.encode_plus(text,max_length=max_len, pad_to_max_length=False,truncation=True, return_tensors=\"pt\")\n",
    "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "  outs = mdl.generate(input_ids=input_ids,attention_mask=attention_mask,early_stopping=True,num_beams=5,num_return_sequences=1,no_repeat_ngram_size=2,max_length=300)\n",
    "  dec = [tknizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
    "  Question = dec[0].replace(\"question:\",\"\")\n",
    "  Question= Question.strip()\n",
    "  return Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGF0o0W5HDSx"
   },
   "source": [
    "## Extracting questions based on the keysentences we generated from the above process.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2q_0CPlnnxl",
    "outputId": "34dc8480-5ac2-404a-e97d-fb7713ae7a00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: Socrates was born in 470 or 469 BC to Sophroniscus and Phaenarete, a stoneworker and a midwife, respectively, in the Athenian deme of Alopece; therefore, he was an Athenian citizen, having been born to relatively affluent Athenians. answer: midwife\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:965: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList(MaxLengthCriteria(max_length=max_length))` instead.\n",
      "  UserWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1830: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: He lived close to his father's relatives and inherited, as was customary, part of his father's estate, securing a life reasonably free of financial concerns. answer: relatives\n",
      "context: His education followed the laws and customs of Athens. answer: customs\n",
      "context: He learned the basic skills of reading and writing and, like most wealthy Athenians, received extra lessons in various other fields such as gymnastics, poetry and music. answer: reading\n"
     ]
    }
   ],
   "source": [
    "questions=[]\n",
    "for words in fill_in_the_blanks['keys']:\n",
    "    for sent in final_sentences:\n",
    "      if words in sent:\n",
    "        ques = get_question(sent,words,question_gen,question_tokenizer)\n",
    "        questions.append(ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKVDV-MFEMNv",
    "outputId": "267b67ff-b55b-4352-d70f-905d24d04d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mRead the following paragraph carefully and answer the provided questions : \n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[31mSocrates was born in 470 or 469 BC to Sophroniscus and Phaenarete, a stoneworker and a midwife, respectively, in the Athenian deme of Alopece; therefore, he was an Athenian citizen, having been born to relatively affluent Athenians.\u001b[0m \n",
      "\n",
      "\u001b[1m\u001b[31mHe lived close to his father's relatives and inherited, as was customary, part of his father's estate, securing a life reasonably free of financial concerns.\u001b[0m \n",
      "\n",
      "\u001b[1m\u001b[31mHis education followed the laws and customs of Athens.\u001b[0m \n",
      "\n",
      "\u001b[1m\u001b[31mHe learned the basic skills of reading and writing and, like most wealthy Athenians, received extra lessons in various other fields such as gymnastics, poetry and music.\u001b[0m \n",
      "\n",
      "\u001b[1m\u001b[31mHe was married twice (which came first is not clear): his marriage to Xanthippe took place when Socrates was in his fifties, and another marriage was with a daughter of Aristides, an Athenian statesman.”\u001b[0m \n",
      "\n",
      "What was Phaenarete's occupation? \n",
      "\n",
      "Who did he live close to? \n",
      "\n",
      "Along with the laws of Athens, what did his education follow? \n",
      "\n",
      "Along with writing, what basic skill did Athens learn? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(colored('Read the following paragraph carefully and answer the provided questions : \\n','blue',attrs=['bold']))\n",
    "wrapped=[print(colored((sentences),'red',attrs=['bold']),'\\n')  for sentences in sent_list]\n",
    "for ques in questions:\n",
    "  print(ques,'\\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Automated generation for knowledge assessments .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
